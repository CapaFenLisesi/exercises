%%%%%%%% Klassen-Optionen
\documentclass[12pt,a4paper]{scrartcl}

%%%%%%%% PAKETE: unverzichtbare Pakete mit Einstellungen
\usepackage[left=2.5cm, right=2cm, top=3cm, bottom=3cm, a4paper]{geometry} %Seitenrände
\usepackage[utf8x]{inputenc} % utf8-Kodierung und direkte Eingabe von Sonderzeichen
\usepackage{fixltx2e} % Verbessert einige Kernkompetenzen von LaTeX2e

%%%%%%%% PAKETE: AMS-Pakete
\usepackage{amsmath} % Mathe-Erweiterung
\usepackage{amsfonts} % Schrift-Erweiterung
\usepackage{amssymb} % Sonderzeichen-Erweiterung

%%%%%%%% PAKETE: Sonstiges
\usepackage[colorlinks, citecolor=black, filecolor=black, linkcolor=black, urlcolor=black]{hyperref} % Links
\usepackage{wrapfig} % ausgeklügekte Floatumgebung
\usepackage{float} % normale Floatumgebung
\restylefloat{figure} % ermöglicht die Verwendung von "H" (ist noch stärker als "h!")
\usepackage[small,it,singlelinecheck=false]{caption} % Bildunterschriften formatieren
\usepackage{multirow} % ermöglich Verbinden von Tabellenzeilen
\usepackage{multicol} % ermöglicht Spalten
\usepackage{fancyhdr} % ermöglicht Kopf- und Fußzeilen
\usepackage{graphicx} % Einbinden von Bildern möglich
\usepackage{units} % Einheiten
 \usepackage{tabularx}%Tabellen
\usepackage{booktabs}
\usepackage{subcaption} % Source code listings
\usepackage{listings}
\lstloadlanguages{python}
% \setkomafont{sectioning}{\normalcolor\sffamily}

%%%%%%%% DEFINITIONEN: Titelseite
\author{April Cooper, Patrick Kreissl und Sebastian Weber}
\title{Worksheet 2: Statistical Mechanics and Molecular Dynamics}
\publishers{University of Stuttgart}
\date{\today}

%%%%%%%% ANPASSUNGEN: Kopf-und Fußzeile
\fancypagestyle{plain}{} % redefine the plain pagestyle to match the fancy layout
\pagestyle{fancy} % aktiviere eigenen Seitenstil
\fancyhf{} % alle Kopf- und Fußzeilen bereinigen
\fancyhead[L]{Worksheet 2: Statistical Mechanics and Molecular Dynamics}
\fancyhead[R]{\today}
\renewcommand{\headrulewidth}{0.6pt} % obere Trennlinie
\fancyfoot[L]{April Cooper, Patrick Kreissl und Sebastian Weber}
\fancyfoot[R]{Page \thepage}
\renewcommand{\footrulewidth}{0.6pt} % untere Trennlinie

%%%%%%%% ANPASSUNGEN: Absätze
\setlength{\parindent}{0em} % keine Absatzeinzüge
\setlength{\parskip}{0em} % Absatz-Abstand

%%%%%%%% ANPASSUNGEN: Abbildungsverzeichnis
\usepackage{tocloft} % Zum Anpassen der Verzeichnisse
\renewcommand{\cftfigpresnum}{Abb. }
\renewcommand{\cfttabpresnum}{Tab. }
\renewcommand{\cftfigaftersnum}{:}
\renewcommand{\cfttabaftersnum}{:}
\setlength{\cftfignumwidth}{2cm}
\setlength{\cfttabnumwidth}{2cm}
\setlength{\cftfigindent}{0cm}
\setlength{\cfttabindent}{0cm}

%%%%%%%% SONSTIGES
\usepackage{pdfpages}
\usepackage{pgf}

% NÜTZLICH: http://truben.no/latex/table/

% Anfang des eigentlichen Dokuments
\begin{document}

\maketitle
\tableofcontents
\newpage

% =============== Section ============
\section{Statistical Mechanics}
\subsection{Task 1}
First we had to consider a system A consisting of two subsystems $A_1$ and $A_2$ with the related numbers of configurations $\Omega_1= 10^20$ and $\Omega_2=10^22$.\\
The number of configurations available to the combined system  is $\Omega=\Omega_1\cdot \Omega_2= 10^{42}$.\\
As the entropy is defined as $S = ln(\Omega)k_B$ the entropies are:\\
$S_1=k_B ln(\Omega_1)=k_B ln(10^{20})$,
$S_2=k_B ln(\Omega_2)=k_B ln(10^{22})$,
$S=k_B ln(\Omega)=k_B ln(10^{42})$.\\
\\
Then were asked to give the factor by which the number of available configurations increases in a system with given initial $V_1,T,p_1$ if $V_1$ was expanded isothermal by 0.001\%.
\\
With the help of the first law of thermodynamics  it follows that for T = const it is:\\
$dS=\frac{p}{T}dV$, which leads with the ideal gas equation to
 \begin{align}
 \Delta S&=\int_{V1}^{V2} \frac{k_BN}{V}dV\nonumber\\
  &= k_BNln\left(\frac{V_2}{V_1}\right)\nonumber\\
  &=10^{-7}k_BN
   \end{align}
  If you consider now the definition of S: $\Delta S = ln( \hat \Delta \Omega)k_B $ you get with equation (1):\\
 \[ \hat \Delta\Omega = exp(\frac{\Delta S}{k_B}) = exp(10^{-7}N)=\frac{\Omega_2}{\Omega_1}\]
 \\
 Finally we were asked to give the factor by which the number of available configurations increases in a system with given initial $N,V,T_1$ when an energy of 150 kJ is  added to the system at constant Volume.\\
 Analogous to the task before it can be derived that $\Delta S = c_vNln\left(\frac{T_2}{T_1}\right)$.
 Using again that the factor by which the number of configurations is given by $\hat \Delta \Omega = exp(\frac{S}{k_B})$ it follows that:\\
 \[\hat \Delta \Omega = exp\left(\frac{c_vNln(\frac{T_2}{T_1})}{k_B}\right)=exp\left(\frac{c_vN}{k_B}\right)\frac{T_2}{T_1} \]\\
Using that $T_2=\frac{\Delta Q}{c_vN}-T_1$ and plugging in the given values leads finally to:\\
\[\hat \Delta \Omega = exp\left(\frac{2c_v}{k_B}\right)\left(\frac{78}{300c_v }-1\right)= \frac{\Omega_2}{\Omega_1}\]

\newpage
\subsection{Task 2 - Thermodynamic Variables in the Canonical Ensemble}
Given the Helmholtz free energy F we were asked to derive expressions for U,p,S.
Using the Maxwell relations it follows:\\
\begin{align}
S&=\frac{-\partial F}{\partial T} = ln(Q(N,V,T))k_B+\frac{k_BT}{Q(N,V,T)}\frac{\partial Q(N,V,T)}{\partial T}\nonumber\\
p&=\frac{-\partial F}{\partial V}=\frac{1}{\beta Q(N,V,T)}\frac{\partial Q(N,V,T)}{\partial V}\nonumber
\end{align}
The derivation of the equation for U is as follows:\\
It is known from statistical mechanics that $Q(N,V,T)= \frac{1}{h^{3N}N!}\int d\Gamma exp(-\beta H)$. The thermodynamic properties of the system can be obtained by $Q(N,V,T)=exp(-\beta F(N,V,T))$. To justify this identification we show fist that F is extensive and then that $F=U-TS$, where $U=\langle H \rangle$.\\
That F is extensive can be derived directly from $Q(N,V,T)= \frac{1}{h^{3N}N!}\int d\Gamma exp(-\beta H)$. When the system is split up into two systems with a very weak corelation, then is Q a product of two factors.
To show the second equivalence we rewrite $F = U -TS $ to $U = \langle H \rangle = A - T\left(\frac{\partial A}{\partial T} \right)$.
To show this we divide the two expressions of Q that we stated before and therefore get:\\
\[\frac{1}{h^{3N}N!}\int d\Gamma exp(\beta (F-H))=1\]
Deriving both sides by $\beta$ leads to:\\
\[ \frac{1}{h^{3N}N!}\int d\Gamma exp(\beta (F-H))(F-H+\beta \left(\frac{\partial F}{\partial \beta}\right))=0\]
This is equivalent to $F - U - T \left(\frac{\partial F}{\partial T}\right)$, wherefore it is: $U= F+TS$.

\subsection{Task 3 - Ideal Gas}
Given the partition function $Q(N,V,T)$ we had to derive expressions for the free Helmholtz energy F(N,V,T) and the pressure p(N,V,T).\\
As we know from task 2 it is $F=\frac{-ln(Q(N,V,T))}{\beta}$.
Plugging in the $Q(N,V,T)$ given on the sheet and using the hint leads to:

 \begin{align}
 F&= -\frac{ln(Q(N,V,T)}{\beta}\nonumber\\
 &= -k_BT  ln\left(\frac{V^N}{\lambda^{3N}N!}\right)\nonumber\\
 &= -k_BT\left(N ln(V) - N ln(\lambda^{3}) - ln(N!)\right)\nonumber\\
 &= -k_BTN\left(ln(V) - ln(\lambda^{3}) -ln(N) + 1\right)\nonumber\\
 &= k_BTN\left(ln\left(\frac{N\lambda^3}{V}\right)-1\right)
 \end{align}
 Applying the Maxwell relation $\frac{-\partial F}{\partial V}=p$ on equation (1) it follows:\\
  \begin{align}
 p&=\frac{-\partial F}{\partial V} \nonumber\\
 &=\frac{-\partial k_BTN\left(ln\left(\frac{N\lambda^3}{V}\right)-1\right) }{\partial V}\nonumber\\
 &=\frac{k_BTN}{V}
 \end{align}
As it is obvious equation(3) leads to the ideal gas law : $pV=Nk_BT$.

\section{Molecular Dynamics: Lennard-Jones Fluid}
\subsection{Implementation of the Lennard Jones Potential}
The Lennard Jones Potential is $V_{LJ}(r)=4\epsilon\left(\left(\frac{\sigma}{r}\right)^{12}-\left(\frac{\sigma}{r}\right)^{6}\right) $ and it's straight forward implementation works as follows:
\lstinputlisting[frame=single,label=LJ_Potential,caption=Function compute\_lj\_potential]{../code_snippets/compute_lj_potential.py}
Consequently the force being the negative gradient of the potential $V_{LJ}$ is  computed by the following function:
\lstinputlisting[frame=single,label=LJ_Force,caption=Function compute\_lj\_force]{../code_snippets/compute_lj_force.py}
To compute the plot of the potential and the first component of the force against d the following routine was implemented:
\lstinputlisting[frame=single,label=LJ_Force,caption=Computation of the potential and force]{../code_snippets/pot_force.py}
Both, the plot of the potential and the force, show a steep increase for $x \rightarrow 0$ and become constant 0 for $x\rightarrow \infty$. This simply reflects the fact that the force and potential increase with declining distances for already small distances and that the interaction of two particles being far apart is negligible.

\begin{figure}[H]
	\resizebox{1\textwidth}{!}{\input{../plots/1_potential_00.pgf}}
	\caption{LJ Potential}\label{fig:Potential_LJ}
\end{figure}
\begin{figure}[H]
	\resizebox{1\textwidth}{!}{\input{../plots/1_potential_01.pgf}}
	\caption{LJ Force}\label{fig:Force_LJ}
\end{figure}
\newpage
\subsection{Lennard-Jones Billards}
In this task we first had to insert the already programmed routines into the given templates. After that we had to run the program and to  visualize the system. The visualization via VMD and the resulting trajectories in the xy-plane are:\\
\begin{minipage}[hbt]{0cm}
\centering
	\input{../plots/2_ljbillards_00.pgf}
	%\caption{Bild2}
	%\label{Bild2}
\end{minipage}
\begin{minipage}[hbt]{15cm}
	\includegraphics[width=5.5cm]{../plots/vmd_2_ljbillards/vmdscene.png}
	%\caption{Bild1}
	%\label{fig:Bild1}
\end{minipage}


As it can be seen in this picture ball 4 has already been moved so that it hits ball 2.
The position needed, that this occurs is: $x[:,4] = [15.4324, 9.51146, 0.0]$

\begin{figure}[H]
	\resizebox{1\textwidth}{!}{\input{../plots/2_ljbillards_01.pgf}}
	\caption{Energy}\label{fig:Energy}
\end{figure}
The energy is constant except from the times when the balls hit each other. In these cases occur relatively small variations in the energy.
As it can be seen in Figure 3 %Achtung, stimmt das noch?
the particles 0, 2 and 4 act just like normal billards balls. However the trajectories of the particles 1 and 3 show that the interaction is not based on a hard sphere potential, which would be exact for a billards ball, but on a potential with an attractive part for certain distances.  This is obvious as the trajectories show that particle 1 influences particle 3 without hitting it directly which results in a curved trajectory of these two balls. After the distance between the balls becomes big enough the attraction is not acting anymore and the particles follow straight trajectories afterwards.

\subsection{Minimum Image Convention and PBC}
First we had to implement the potential and the force such that it implements the truncated LJ potential for $r_cutoff=2.5$.
The straight forward implementation is analogous to the function implemented before:
\lstinputlisting[frame=single,label=LJ_Potential,caption=Function compute\_lj\_potential]{../code_snippets/LJ_pot_trunc.py}
\lstinputlisting[frame=single,label=LJ_Force,caption=Function compute\_lj\_force]{../code_snippets/LJ_force_trunc.py}
In order to implement PBC some of the routines have to be changed.
First of all the function compute\_forces had to be updated in order to fulfill the minimum image convention.
\lstinputlisting[frame=single,label=CF_PBC,caption=Function compute\_forces]{../code_snippets/CF_PBC.py}
In this case the function \verb rint() takes an array and rounds the entries to the closest integer. 
The same modification had to be done in the function compute\_energy, meaning that \verb rij had again to be rounded with the help of \verb rint .
As no other things are changed we ask the reader to have a look in the source code in the appendix in order to see the whole function. 
Another change had to be done in the main loop.
As not all particles considered in the box the positions x had to be folded back into the central box.
This is done as follows:
\lstinputlisting[frame=single,label=back fold,caption=Folding x back into the central box]{../code_snippets/folding_x.py}
Finally also the trajectories had to be folded back before being plotted.
As it works just as the back folding of x we again ask the reader to have a closer look at the source code for further information.
Now the implemented PBC were tested using a simulation of LJ billards balls. 
The main loop of the program is implemented as
\lstinputlisting[frame=single,label=PBC test,caption=Test of the PBC using ljbillards ]{../code_snippets/main_pbc.py}
The resulting trajectories are:
\begin{figure}[H]
	\resizebox{1\textwidth}{!}{\input{../plots/3_periodic_00.pgf}}
	\caption{Trajectories of the two particles for 20 timesteps}\label{fig:Traj_PBC}
\end{figure}
\begin{figure}[H]
	\resizebox{1\textwidth}{!}{\input{../plots/3_periodic_01.pgf}}
	
	\caption{Energy - truncated potential}\label{fig:Energy}
\end{figure}
In the plot of the trajectories it becomes obvious that the PBC work, as when a particle leaves the box on one side the trajectory seems, after being folded back into the central box, to continue on the opposite side. Again the energy stays constant and shows that the particles hit each other thrice during the simulation time, which can be seen at the sharp energy peaks that have already been described before. 
\newpage
\section{Lennard- Jones Fluid}
\subsection{Pure Python}
First we had to extend the program \verb ljfluid.py to set up the particles on a cubic lattice given the Number n of particles per side and their density $\rho$.
The implementation of this is the following:
\lstinputlisting[frame=single,label=Cubic Lattice,caption=Placing Particles on a Cubic Lattice]{../code_snippets/cubic_lattice.py}

\subsubsection{Timings}
The measured timings are given in the following table:\\

\begin{center}
\begin{tabular}{c c}\toprule
n&time [s]\\ \midrule
3&2.628\\
4&13.081\\
5&44.11\\ \bottomrule
\end{tabular}
\end{center}

It can be seen that the time needed to do the simulations is basically proportional to $n^3$ which would be expected as we have three nested for loops over $n$ in our computation of the positions on the cubic lattice and no other function has a higher complexity.
\newpage
\subsection{Pure C/C++}
First we had to implement the function \verb compute_energy() in C:
\lstinputlisting[frame=single,label=compute energy,caption=Computing the energy]{../code_snippets/comp_e.py}
The total energy is put in the file $ ljfluid\_c.dat$. From the values in the file it can be seen that the energy fluctuates during the simulation time about 5\%. This is supposedly because the system size L is quite small.

\subsubsection{Timing}
The measured timings are given in the following table:\\

\begin{center}
\begin{tabular}{c c}\toprule
n&time [s]\\ \midrule
5&0.148\\
6&0.342\\
7&0.584\\ 
8&1.052\\
9&1.892\\
10&3.11\\
11&5.11\\
12&8.121\\ \bottomrule
\end{tabular}
\end{center}
Compared to the timings in Python measured for $n\le5$ the timings of the C code are much lower even for $n>5$. 
The comparison of the timings for $n=5$ shows the great difference between the run times of these two codes.
As the Python code was running 44.11 s the C code only ran 0.148 s which is significantly lesser.
Further more it can be observed that the time is not scaling with $n^3$ as in the Python code but seems to increase somehow quadratic. This can also be seen in the plot:
\begin{figure}[H]
\centering
\includegraphics[width=12.0cm]{../plots/timing.png}
\caption{Timing of the simulation evolving with $n$}
\label{fig:Timing of the simulation}
\end{figure}

\subsection{Mixing C/C++ and Python}
In thissection we mixed c and Python code. Our task was it to use the C code to measure the energy simulated with the code mixture. The resulting energy is:

\begin{figure}[H]
	\resizebox{1\textwidth}{!}{\input{../plots/4_ljfluid_00.pgf}}
	
	\caption{Energy of the system}\label{fig:Energy of the system}
\end{figure}
Again it can be seen that the energy fluctuates a bit, but as the fluctuations are less than 1\%, it's basically constant.

\subsubsection{Timing}

\begin{center}
\begin{tabular}{c c c}\toprule
n&time C [s]&tim Cython[s]\\ \midrule
5&0.148&0.416\\
10&3.11&3.896\\ \bottomrule
\end{tabular}
\end{center}
As it can be seen the timings for Cython are a bit greater than those for plain C, but Cython outperforms pure Python by far. As the variation in these two timings is quite small it can be said, that it is useful to use Cython as it's much more convenient than c and not significantly slower.
\subsection{Neighborhood Lists}
Using Cython we have up to now the problem that the scaling of the timings is still unfavorable. In order to improve this we introduced neighborhood lists. Which great effect these have on the simulation time can be seen in the following paragraph. 
\subsubsection{Timings}
\begin{center}
\begin{tabular}{c c}\toprule
n&time [s]\\ \midrule
5&0.376\\
10&1.352\\
15&4.088\\ 
20&9.777\\
 \bottomrule
\end{tabular}
\end{center}
If you compare the timings of the simulation with and without neighborhood lists for $n=5$ and $n=10$ it becomes clear that introducing neighborhood lists reduced the timing approximately by a factor 4 respectively 3  which is quite a lot. Therefore it is indeed useful and worthwhile to introduce neighborhood lists even though this means some more implementation. 

\end{document}


% =============== Comments ============
\begin{comment}
\verb{x_init {}}

\begin{figure}[H]
	\resizebox{1\textwidth}{!}{\input{../plots/1_potentoal_00.pgf}}
	\caption{CAPTION}\label{fig:NAME}
\end{figure}

\end{comment}
